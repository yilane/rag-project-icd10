#!/usr/bin/env python3
"""
åŒ»å­¦å‘½åå®ä½“è¯†åˆ«æœåŠ¡
åŸºäº lixin12345/chinese-medical-ner å¤§æ¨¡å‹
ç”¨äºè¯†åˆ«å’Œæå–åŒ»å­¦æ–‡æœ¬ä¸­çš„å…³é”®å®ä½“
"""

import os
import re
from typing import Dict, List, Optional, Any
from loguru import logger
from services.diagnosis_entity_filter import DiagnosisEntityFilter


class MedicalNERService:
    """åŒ»å­¦å‘½åå®ä½“è¯†åˆ«æœåŠ¡"""
    
    def __init__(self, model_name: str = None, use_model: bool = None):
        """
        åˆå§‹åŒ–åŒ»å­¦NERæœåŠ¡
        
        Args:
            model_name: NERæ¨¡å‹åç§°ï¼Œé»˜è®¤ä½¿ç”¨ lixin12345/chinese-medical-ner
            use_model: æ˜¯å¦ä½¿ç”¨å¤§æ¨¡å‹ï¼Œä»ç¯å¢ƒå˜é‡è¯»å–
        """
        # æ¨¡å‹é…ç½®
        if model_name is None:
            model_name = os.getenv('MEDICAL_NER_MODEL', 'lixin12345/chinese-medical-ner')
        
        if use_model is None:
            use_model = os.getenv('USE_MEDICAL_NER_MODEL', 'true').lower() == 'true'
        
        self.model_name = model_name
        self.use_model = use_model
        self.ner_pipeline = None
        self.model = None
        self.tokenizer = None
        
        # åˆå§‹åŒ–è¯Šæ–­å®ä½“è¿‡æ»¤å™¨
        self.entity_filter = DiagnosisEntityFilter()
        
        # å®ä½“ç±»å‹æ˜ å°„ï¼ˆä»æ¨¡å‹æ ‡ç­¾åˆ°æ ‡å‡†ç±»å‹ï¼‰
        self.entity_type_mapping = {
            'DiseaseNameOrComprehensiveCertificate': 'disease',
            'Symptom': 'symptom', 
            'BodyParts': 'anatomy',
            'OrganOrCellDamage': 'pathology',
            'Drug': 'drug',
            'TreatmentOrPreventionProcedures': 'treatment',
            'TreatmentEquipment': 'equipment',
            'InspectionProcedure': 'inspection',
            'MedicalTestingItems': 'lab_indicator',
            'Department': 'department',
            'Sign': 'sign',
            'InjuryOrPoisoning': 'injury',
            'Microbiology': 'microbiology',
            'MedicalProcedures': 'procedure',
            'InspectEquipment': 'inspect_equipment'
        }
        
        # åˆå§‹åŒ–æ¨¡å‹
        if self.use_model:
            self._init_ner_model()
        else:
            logger.info("æœªå¯ç”¨å¤§æ¨¡å‹NERï¼Œå°†ä½¿ç”¨è§„åˆ™æ–¹æ³•ä½œä¸ºå›é€€")
            self._init_fallback_patterns()
    
    def _init_ner_model(self):
        """åˆå§‹åŒ–NERæ¨¡å‹"""
        try:
            from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline
            
            logger.info(f"æ­£åœ¨åŠ è½½åŒ»å­¦NERæ¨¡å‹: {self.model_name}")
            
            # åŠ è½½åˆ†è¯å™¨å’Œæ¨¡å‹
            self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)
            self.model = AutoModelForTokenClassification.from_pretrained(self.model_name)
            
            # è‡ªåŠ¨æ£€æµ‹GPUå¯ç”¨æ€§
            import torch
            device = 0 if torch.cuda.is_available() else -1
            
            # åˆ›å»ºNER pipeline
            self.ner_pipeline = pipeline(
                "ner",
                model=self.model,
                tokenizer=self.tokenizer,
                aggregation_strategy="simple",
                device=device
            )
            
            logger.info(f"åŒ»å­¦NERæ¨¡å‹åŠ è½½æˆåŠŸ: {self.model_name}")
            
        except Exception as e:
            logger.error(f"åŒ»å­¦NERæ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            logger.warning("å›é€€åˆ°è§„åˆ™æ–¹æ³•")
            self.use_model = False
            self.ner_pipeline = None
            self.model = None
            self.tokenizer = None
            self._init_fallback_patterns()
    
    def _init_fallback_patterns(self):
        """åˆå§‹åŒ–å›é€€çš„è§„åˆ™æ¨¡å¼"""
        self.medical_patterns = {
            # ç–¾ç—…æ¨¡å¼
            'disease': [
                r'(?:æ€¥æ€§|æ…¢æ€§|åŸå‘æ€§|ç»§å‘æ€§|å¤å‘æ€§|äºšæ€¥æ€§)?[^ï¼Œã€‚ï¼›\s]{2,12}(?:ç—…|ç—‡|ç‚|ç™Œ|ç˜¤|ç»¼åˆå¾)',
                r'(?:æ€¥æ€§|æ…¢æ€§)?[^ï¼Œã€‚ï¼›\s]{2,8}(?:æ„ŸæŸ“|ä¸­æ¯’|æŸä¼¤|ç ´è£‚|æ¢—æ­»|å‡ºè¡€)',
                r'(?:I|II|III|IV|V)+å‹[^ï¼Œã€‚ï¼›\s]{2,8}(?:ç—…|ç—‡)',
                r'[^ï¼Œã€‚ï¼›\s]{2,8}(?:åŠŸèƒ½ä¸å…¨|åŠŸèƒ½éšœç¢|è¡°ç«­)',
            ],
            
            # ç—‡çŠ¶æ¨¡å¼  
            'symptom': [
                r'(?:åå¤|æŒç»­|é—´æ­‡æ€§|çªå‘æ€§)?[^ï¼Œã€‚ï¼›\s]{2,6}(?:ç—›|ç–¼|çƒ­|èƒ€|è‚¿|æ™•|éº»|ç—’)',
                r'(?:å¤§é‡|å°‘é‡|è¡€æ€§|è„“æ€§)?[^ï¼Œã€‚ï¼›\s]{2,6}(?:å‡ºè¡€|åˆ†æ³Œ|å‘•å|è…¹æ³»)',
                r'[^ï¼Œã€‚ï¼›\s]{2,6}(?:ä¸é€‚|å¼‚å¸¸|å¢å¤§|ç¼©å°|è‚¥åš)',
                r'(?:é˜µå‘æ€§|æŒç»­æ€§)?[^ï¼Œã€‚ï¼›\s]{2,6}(?:å’³å—½|æ°”ä¿ƒ|å¿ƒæ‚¸|å¤±çœ )',
            ],
            
            # è§£å‰–éƒ¨ä½æ¨¡å¼
            'anatomy': [
                r'(?:å·¦|å³|åŒä¾§|ä¸Š|ä¸‹|å‰|å)?(?:å¿ƒ|è‚|è‚º|è‚¾|èƒƒ|è‚ |è„‘|éª¨|è„ŠæŸ±)[^ï¼Œã€‚ï¼›\s]{0,6}',
                r'(?:å·¦|å³|åŒä¾§)?(?:ä¹³è…º|ç”²çŠ¶è…º|å‰åˆ—è…º|å­å®«|åµå·¢)[^ï¼Œã€‚ï¼›\s]{0,4}',
                r'(?:é¢ˆ|èƒ¸|è…°|éª¶|å°¾)æ¤[^ï¼Œã€‚ï¼›\s]{0,4}',
                r'(?:ä¸»|å† çŠ¶|è‚º|è‚¾)åŠ¨è„‰[^ï¼Œã€‚ï¼›\s]{0,4}',
            ]
        }
        
        # åœç”¨è¯åˆ—è¡¨
        self.stop_words = {
            'å¾…æŸ¥', 'è€ƒè™‘', 'ç–‘ä¼¼', 'æ’é™¤', 'ï¼Ÿ', '?', 'è¯Šæ–­ä¸º', 'æ‚£è€…', 'ç—…äºº',
            'æ£€æŸ¥', 'å‘ç°', 'æ˜¾ç¤º', 'æç¤º', 'å»ºè®®', 'éœ€è¦', 'è¿›ä¸€æ­¥', 'å¤æŸ¥',
            'æ²»ç–—', 'ç”¨è¯', 'æœç”¨', 'æ³¨å°„', 'è¾“æ¶²', 'æ‰‹æœ¯', 'åº·å¤'
        }
        
        # æ— æ„ä¹‰çŸ­è¯­
        self.meaningless_phrases = {
            'ä¸è¯¦', 'ä¸æ˜', 'ä¸æ¸…', 'æœªæ˜ç¡®', 'å¾…å®š', 'è§‚å¯Ÿ', 'éšè®¿'
        }
    
    def extract_medical_entities(self, text: str, filter_drugs: bool = True) -> Dict[str, List[Dict[str, Any]]]:
        """
        æå–åŒ»å­¦å®ä½“ï¼ˆæ”¯æŒå¤§æ¨¡å‹å’Œè§„åˆ™æ–¹æ³•ï¼‰
        
        Args:
            text: è¾“å…¥çš„åŒ»å­¦æ–‡æœ¬
            filter_drugs: æ˜¯å¦è¿‡æ»¤éè¯Šæ–­å®ä½“ï¼ˆè¯å“ã€è®¾å¤‡ã€ç§‘å®¤ç­‰ï¼‰ï¼Œé»˜è®¤True
            
        Returns:
            å­—å…¸ï¼Œé”®ä¸ºå®ä½“ç±»å‹ï¼Œå€¼ä¸ºå®ä½“åˆ—è¡¨ï¼ˆåŒ…å«text, start, end, confidenceï¼‰
        """
        if not text or not text.strip():
            return {}
        
        logger.debug(f"å¼€å§‹æå–åŒ»å­¦å®ä½“: {text}")
        
        # ä¼˜å…ˆä½¿ç”¨å¤§æ¨¡å‹
        if self.use_model and self.ner_pipeline:
            try:
                entities = self._extract_entities_with_model(text)
            except Exception as e:
                logger.warning(f"å¤§æ¨¡å‹NERå¤±è´¥ï¼Œå›é€€åˆ°è§„åˆ™æ–¹æ³•: {e}")
                entities = self._extract_entities_with_rules(text)
        else:
            # ä½¿ç”¨è§„åˆ™æ–¹æ³•
            entities = self._extract_entities_with_rules(text)
        
        # å¦‚æœéœ€è¦è¿‡æ»¤éè¯Šæ–­å®ä½“ï¼ˆè¯å“ã€è®¾å¤‡ã€ç§‘å®¤ç­‰ï¼‰
        if filter_drugs:
            logger.debug("å¼€å§‹è¿‡æ»¤éè¯Šæ–­å®ä½“")
            entities = self.entity_filter.filter_entities(entities, text)
        
        return entities
    
    def _extract_entities_with_model(self, text: str) -> Dict[str, List[Dict[str, Any]]]:
        """ä½¿ç”¨å¤§æ¨¡å‹æå–å®ä½“"""
        logger.debug(f"ä½¿ç”¨å¤§æ¨¡å‹æå–å®ä½“: {text}")
        
        # ä½¿ç”¨NER pipelineè¿›è¡Œå®ä½“è¯†åˆ«
        model_entities = self.ner_pipeline(text)
        
        # è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼
        entities = {}
        
        for entity in model_entities:
            # è·å–å®ä½“ä¿¡æ¯
            entity_text = entity['word'].replace(' ', '').replace('##', '')  # æ¸…ç†tokenizer artifacts
            entity_label = entity['entity_group'] if 'entity_group' in entity else entity['entity']
            confidence = entity['score']
            start = entity.get('start', 0)
            end = entity.get('end', len(entity_text))
            
            # æ˜ å°„åˆ°æ ‡å‡†å®ä½“ç±»å‹
            standard_type = self.entity_type_mapping.get(entity_label, 'other')
            
            # è¿‡æ»¤ä½è´¨é‡å®ä½“
            if not self._is_valid_model_entity(entity_text, confidence):
                continue
            
            # æ·»åŠ åˆ°ç»“æœ
            if standard_type not in entities:
                entities[standard_type] = []
            
            entity_info = {
                'text': entity_text,
                'start': start,
                'end': end,
                'confidence': confidence,
                'original_label': entity_label,
                'source': 'model'
            }
            entities[standard_type].append(entity_info)
        
        # å»é‡å’Œæ’åº
        for entity_type in entities:
            entities[entity_type] = self._deduplicate_entities(entities[entity_type])
        
        total_entities = sum(len(v) for v in entities.values())
        logger.info(f"å¤§æ¨¡å‹æå–åˆ° {total_entities} ä¸ªå®ä½“")
        
        # è¯¦ç»†è®°å½•æ¯ç§ç±»å‹çš„å®ä½“
        for entity_type, entity_list in entities.items():
            if entity_list:
                entity_details = [f"{e['text']}({e['confidence']:.3f})" for e in entity_list]
                logger.info(f"  {entity_type}: {entity_details}")
        
        return entities
    
    def _extract_entities_with_rules(self, text: str) -> Dict[str, List[Dict[str, Any]]]:
        """ä½¿ç”¨è§„åˆ™æ–¹æ³•æå–å®ä½“"""
        logger.debug(f"ä½¿ç”¨è§„åˆ™æ–¹æ³•æå–å®ä½“: {text}")
        
        entities = {}
        
        for entity_type, patterns in self.medical_patterns.items():
            entities[entity_type] = []
            
            for pattern in patterns:
                matches = list(re.finditer(pattern, text))
                
                for match in matches:
                    entity_text = match.group().strip()
                    
                    # è¿‡æ»¤æ— æ•ˆå®ä½“
                    if self._is_valid_entity(entity_text):
                        entity_info = {
                            'text': entity_text,
                            'start': match.start(),
                            'end': match.end(),
                            'confidence': self._calculate_entity_confidence(entity_text, entity_type),
                            'pattern': pattern,
                            'source': 'rules'
                        }
                        entities[entity_type].append(entity_info)
        
        # å»é‡å’Œæ’åº
        for entity_type in entities:
            entities[entity_type] = self._deduplicate_entities(entities[entity_type])
        
        logger.info(f"è§„åˆ™æ–¹æ³•æå–åˆ° {sum(len(v) for v in entities.values())} ä¸ªå®ä½“")
        return entities
    
    def _is_valid_model_entity(self, entity_text: str, confidence: float) -> bool:
        """éªŒè¯å¤§æ¨¡å‹æå–çš„å®ä½“æ˜¯å¦æœ‰æ•ˆ"""
        if not entity_text or len(entity_text) < 2:
            return False
        
        # ç½®ä¿¡åº¦é˜ˆå€¼
        min_confidence = float(os.getenv('MEDICAL_NER_MIN_CONFIDENCE', '0.5'))
        if confidence < min_confidence:
            return False
        
        # è¿‡æ»¤æ— æ„ä¹‰æ–‡æœ¬ï¼ˆå¦‚æœæœ‰åœç”¨è¯åˆ—è¡¨ï¼‰
        if hasattr(self, 'stop_words') and entity_text in self.stop_words:
            return False
        
        return True
    
    def _is_valid_entity(self, entity_text: str) -> bool:
        """åˆ¤æ–­å®ä½“æ˜¯å¦æœ‰æ•ˆ"""
        if not entity_text or len(entity_text) < 2:
            return False
        
        # è¿‡æ»¤åœç”¨è¯å’Œæ— æ„ä¹‰çŸ­è¯­
        if entity_text in self.stop_words or entity_text in self.meaningless_phrases:
            return False
        
        # è¿‡æ»¤çº¯æ•°å­—æˆ–çº¯ç¬¦å·
        if re.match(r'^[\d\s\-+.]+$', entity_text):
            return False
        
        return True
    
    def _calculate_entity_confidence(self, entity_text: str, entity_type: str) -> float:
        """è®¡ç®—å®ä½“ç½®ä¿¡åº¦"""
        confidence = 0.5  # åŸºç¡€ç½®ä¿¡åº¦
        
        # é•¿åº¦å› å­
        if len(entity_text) >= 4:
            confidence += 0.1
        if len(entity_text) >= 6:
            confidence += 0.1
        
        # ç‰¹å¾è¯åŠ æƒ
        if entity_type == 'disease':
            if any(suffix in entity_text for suffix in ['ç—…', 'ç—‡', 'ç‚', 'ç™Œ', 'ç˜¤']):
                confidence += 0.2
            if any(prefix in entity_text for prefix in ['æ€¥æ€§', 'æ…¢æ€§', 'åŸå‘æ€§']):
                confidence += 0.1
        
        elif entity_type == 'symptom':
            if any(suffix in entity_text for suffix in ['ç—›', 'çƒ­', 'èƒ€', 'è‚¿', 'å‡ºè¡€']):
                confidence += 0.2
        
        elif entity_type == 'anatomy':
            if any(part in entity_text for part in ['å¿ƒ', 'è‚', 'è‚º', 'è‚¾', 'è„‘']):
                confidence += 0.2
        
        return min(confidence, 1.0)
    
    def _deduplicate_entities(self, entities: List[Dict]) -> List[Dict]:
        """å»é‡å®ä½“åˆ—è¡¨"""
        if not entities:
            return []
        
        # æŒ‰ä½ç½®æ’åº
        entities.sort(key=lambda x: (x['start'], -x['confidence']))
        
        # å»é‡é€»è¾‘ï¼šå¦‚æœä¸¤ä¸ªå®ä½“é‡å ï¼Œä¿ç•™ç½®ä¿¡åº¦æ›´é«˜çš„
        deduplicated = []
        for entity in entities:
            is_duplicate = False
            
            for existing in deduplicated:
                # æ£€æŸ¥æ˜¯å¦é‡å 
                if (entity['start'] < existing['end'] and 
                    entity['end'] > existing['start']):
                    # å¦‚æœå½“å‰å®ä½“ç½®ä¿¡åº¦æ›´é«˜ï¼Œæ›¿æ¢ç°æœ‰å®ä½“
                    if entity['confidence'] > existing['confidence']:
                        deduplicated.remove(existing)
                        deduplicated.append(entity)
                    is_duplicate = True
                    break
            
            if not is_duplicate:
                deduplicated.append(entity)
        
        # æŒ‰ç½®ä¿¡åº¦æ’åº
        return sorted(deduplicated, key=lambda x: x['confidence'], reverse=True)
    
    def identify_diagnosis_keywords(self, text: str) -> List[str]:
        """
        è¯†åˆ«è¯Šæ–­å…³é”®è¯ï¼ˆç”¨äºå‘åå…¼å®¹ï¼‰
        
        Args:
            text: è¾“å…¥æ–‡æœ¬
            
        Returns:
            è¯Šæ–­å…³é”®è¯åˆ—è¡¨
        """
        entities = self.extract_medical_entities(text)
        keywords = []
        
        # ä¼˜å…ˆæå–ç–¾ç—…å®ä½“
        for entity in entities.get('disease', []):
            confidence_threshold = 0.5 if self.use_model else 0.6
            if entity['confidence'] > confidence_threshold:
                keywords.append(entity['text'])
        
        # å¦‚æœæ²¡æœ‰ç–¾ç—…å®ä½“ï¼Œæå–ç—‡çŠ¶å®ä½“
        if not keywords:
            for entity in entities.get('symptom', []):
                confidence_threshold = 0.6 if self.use_model else 0.7
                if entity['confidence'] > confidence_threshold:
                    keywords.append(entity['text'])
        
        return keywords
    
    def get_model_info(self) -> Dict[str, Any]:
        """è·å–æ¨¡å‹ä¿¡æ¯"""
        # æ£€æµ‹GPUå¯ç”¨æ€§
        try:
            import torch
            gpu_available = torch.cuda.is_available()
            gpu_device_count = torch.cuda.device_count() if gpu_available else 0
        except ImportError:
            gpu_available = False
            gpu_device_count = 0
        
        return {
            'model_name': self.model_name,
            'use_model': self.use_model,
            'model_loaded': self.ner_pipeline is not None,
            'entity_types': list(self.entity_type_mapping.keys()) if self.use_model else list(self.medical_patterns.keys()),
            'fallback_available': hasattr(self, 'medical_patterns'),
            'gpu_available': gpu_available,
            'gpu_device_count': gpu_device_count,
            'device': 'GPU' if gpu_available and self.use_model else 'CPU'
        }
    
    def get_entity_summary(self, text: str) -> Dict[str, any]:
        """
        è·å–å®ä½“æå–æ‘˜è¦
        
        Args:
            text: è¾“å…¥æ–‡æœ¬
            
        Returns:
            å®ä½“æ‘˜è¦ä¿¡æ¯
        """
        entities = self.extract_medical_entities(text)
        
        summary = {
            'total_entities': sum(len(entities[key]) for key in entities),
            'entity_types': list(entities.keys()),
            'high_confidence_entities': [],
            'primary_diagnosis_candidates': [],
            'extraction_method': 'model' if self.use_model and self.ner_pipeline else 'rules',
            'model_info': self.get_model_info()
        }
        
        # åŠ¨æ€ç½®ä¿¡åº¦é˜ˆå€¼
        high_confidence_threshold = 0.8 if self.use_model else 0.7
        diagnosis_threshold = 0.5 if self.use_model else 0.6
        
        # ç»Ÿè®¡é«˜ç½®ä¿¡åº¦å®ä½“
        for entity_type, entity_list in entities.items():
            for entity in entity_list:
                if entity['confidence'] > high_confidence_threshold:
                    summary['high_confidence_entities'].append({
                        'type': entity_type,
                        'text': entity['text'],
                        'confidence': entity['confidence'],
                        'source': entity.get('source', 'unknown')
                    })
        
        # è¯†åˆ«ä¸»è¦è¯Šæ–­å€™é€‰
        disease_entities = entities.get('disease', [])
        if disease_entities:
            summary['primary_diagnosis_candidates'] = [
                entity['text'] for entity in disease_entities[:3]
                if entity['confidence'] > diagnosis_threshold
            ]
        
        return summary
    
    def get_filter_stats(self, text: str) -> Dict[str, Any]:
        """
        è·å–è¿‡æ»¤ç»Ÿè®¡ä¿¡æ¯
        
        Args:
            text: è¾“å…¥æ–‡æœ¬
            
        Returns:
            è¿‡æ»¤ç»Ÿè®¡ä¿¡æ¯
        """
        # è·å–æœªè¿‡æ»¤çš„å®ä½“
        original_entities = self.extract_medical_entities(text, filter_drugs=False)
        
        # è·å–è¿‡æ»¤åçš„å®ä½“ï¼ˆè¿‡æ»¤éè¯Šæ–­å®ä½“ï¼‰
        filtered_entities = self.extract_medical_entities(text, filter_drugs=True)
        
        # ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯
        stats = self.entity_filter.get_filter_stats(original_entities, filtered_entities)
        
        return stats


def main():
    """æµ‹è¯•å‡½æ•°"""
    print("=== åŒ»å­¦NERæœåŠ¡æµ‹è¯• ===")
    
    # æµ‹è¯•å¤§æ¨¡å‹ç‰ˆæœ¬
    print("\nğŸ¤– æµ‹è¯•å¤§æ¨¡å‹NERæœåŠ¡:")
    model_ner_service = MedicalNERService(use_model=True)
    print(f"æ¨¡å‹ä¿¡æ¯: {model_ner_service.get_model_info()}")
    
    # æµ‹è¯•è§„åˆ™ç‰ˆæœ¬
    print("\nğŸ“ æµ‹è¯•è§„åˆ™NERæœåŠ¡:")
    rule_ner_service = MedicalNERService(use_model=False)
    print(f"è§„åˆ™ä¿¡æ¯: {rule_ner_service.get_model_info()}")
    
    test_cases = [
        "æ€¥æ€§å¿ƒè‚Œæ¢—æ­»ä¼´å¿ƒå¾‹å¤±å¸¸",
        "æ…¢æ€§è‚¾åŠŸèƒ½ä¸å…¨ é«˜è¡€å‹ç—…3çº§ ç³–å°¿ç—…",
        "ç–‘ä¼¼æ€¥æ€§èƒƒè‚ ç‚ï¼Œä¼´å‘çƒ­è…¹æ³»ç—‡çŠ¶",
        "å·¦è‚ºä¸Šå¶è‚ºç™Œ èƒ¸è…”ç§¯æ¶² å‘¼å¸å›°éš¾",
        "2å‹ç³–å°¿ç—…ä¼´è¡€ç³–æ§åˆ¶ä¸ä½³ è›‹ç™½å°¿å¾…æŸ¥",
    ]
    
    for i, test_text in enumerate(test_cases, 1):
        print(f"\n=== æµ‹è¯•æ¡ˆä¾‹ {i}: {test_text} ===")
        
        # å¤§æ¨¡å‹ç‰ˆæœ¬
        if model_ner_service.use_model:
            print("ğŸ¤– å¤§æ¨¡å‹ç»“æœ:")
            entities = model_ner_service.extract_medical_entities(test_text)
            for entity_type, entity_list in entities.items():
                if entity_list:
                    entity_info = [(e['text'], f"{e['confidence']:.3f}") for e in entity_list[:3]]
                    print(f"  {entity_type}: {entity_info}")
            
            summary = model_ner_service.get_entity_summary(test_text)
            print(f"  æ‘˜è¦: {summary['total_entities']}ä¸ªå®ä½“, é«˜ç½®ä¿¡åº¦{len(summary['high_confidence_entities'])}ä¸ª")
        
        # è§„åˆ™ç‰ˆæœ¬å¯¹æ¯”
        print("ğŸ“ è§„åˆ™æ–¹æ³•ç»“æœ:")
        entities = rule_ner_service.extract_medical_entities(test_text)
        for entity_type, entity_list in entities.items():
            if entity_list:
                entity_info = [(e['text'], f"{e['confidence']:.3f}") for e in entity_list[:3]]
                print(f"  {entity_type}: {entity_info}")


if __name__ == "__main__":
    main()